# Image-Processing-Local-Thresholding
OPENCV

LOCAL THRESHOLDING
     A local adaptive threshold is used to convert an image consisting of gray scale pixels to only black and white scale pixels. Usually, a pixel value of 0 represents white, a value of 255 represents black, and the numbers 1 to 254 represent different levels of gray. Unlike the global thresholding technique, local adaptive thresholding selects different threshold values ​​for each pixel in the image based on the analysis of neighboring pixels. This is to allow images with different contrast levels for which a global thresholding technique would not work satisfactorily. Thresholding is used to segment an image by setting all pixels with intensity values ​​above a threshold to a foreground value and all remaining pixels to a background value.
     An alternative approach to finding the local threshold is to statistically examine the intensity values ​​of the local neighborhood of each pixel. The most appropriate statistic is highly dependent on the input picture. Simple and fast functions include averaging the local density distribution.
     In all the images I have used, I show the local adaptive threshold in different sections. Locally, I show only the single algorithm and neighborhood values ​​that give the best results to each section.
     A task well suited to native adaptive thresholding is to segment text from the image. In order to show this application, I aimed to show the global threshold applications locally by dividing an old-dated newspaper clipping with different light angles, shadows and colors into 9 equal parts.
     There are 3 algorithms that I have used in my newspaper image, these are THRESH_OTSU, ADAPTIVE_THRESH_MEAN_C and ADAPTIVE_THRESH_GAUSSIAN_C algorithms. I have divided the image into sections and selected the algorithms that will meet the needs separately and completely for each section. I think that it will be more understandable to determine which algorithm improves how much by showing the image separately. I tried to make adjustments on the image by changing the neighborhood values ​​of these algorithms. Especially in this image, which is an old newspaper clipping, the light distribution is uneven, the font and the shooting angle are not smooth. But despite all the negativities, I think I got a good image.
     
The light distribution is not made evenly throughout the image, and a pale and asymmetrical shot is made. Considering these conditions, I divided the image into 9 equal parts and determined the algorithms and values ​​that gave the best results on each image. Finally, if we comment;
     In R2,R5,R7,R8 sections where the texts are the majority, I got very good results in terms of readability of the ADAPTIVE_MEAN_C algorithm font. The values ​​I have given vary according to the fluctuation of the light. There is also text in the R9 section, but in that section, I needed to get a clearer view, since it was annotated with a different writing style and an additional paper, because I used the ADAPTIVE_THRESH_GAUSSIAN_C algorithm to reveal finer details, since it is not as thick and clear as the other font. . I obtained a clearer view by using the THRESH_OTSU algorithm, which allows the images to appear clearer in the parts and since fine details are not included. Since I use the THRESH_OTSU algorithm because it is visual in the R4 section, the font produces more unsuccessful results compared to other sections.
     For this image, ADAPTIVE_THRESH_MEAN_C should be used mostly in the parts where the texts are located, ADAPTIVE_THRESH_GAUSSIAN_C should be used in the part where the text font is not more pronounced, and the THRESH_OTSU algorithm gave successful results since the images do not require details.
     
Our next image is a leopard image, which is one of the wildlife photos photographed under harsh conditions. In this leopard image, the background was blurred by the photographer and the leopard was wanted to appear more clearly. Therefore, we can observe that the ADAPTIVE_MEAN_C algorithm, which we saw in the R1 section in this image, gives more successful results in order to reveal the details. When I use Gaussian in R1 and R3 sections, bush leaves do not appear. In the R2 and R3 sections, I observed that the bushes that are not visible as a result of blurring the back side give good results with the ADAPTIVE_MEAN_C algorithm. When I use the GAUSSIAN_C algorithm, the outer wall of the plant becomes indistinct and in the OTSU algorithm, the background is almost not visible. Since the leopard image is a detailed image, I paid attention to the appearance of each speckle detail, and the feathers on the muzzle and chin of the leopard are clearly observed in R5. In the OTSU algorithm, the spots of the leopard appeared as a whole and the tiny black spots that formed between them disappeared under this blackness. I have solved this problem with ADAPTIVE_MEAN_C (17.3) values. I got successful results with the ADAPTIVE_MEAN_C algorithm in this section, as it makes the Gaussian spots whiter and tiny spots do not appear.

THRESHOLD IN HEALTH
     In this image, I aim to make the brain tumor image, which is indicated in different colors, prominent with local threshold values. In this image, we almost completely destroy the details of the brain image with the global threshold values, only a small part of the tumor can be seen indistinctly, but it is not an adequate image for our healthcare professionals. When the OTSU algorithm is applied to the image, we completely lose the image. However, since it is an image to be used in the detection of a very important disease, I preferred to use the ADAPTIVE_MEAN_C algorithm, which gives us more detailed results. I aimed to observe an image in which the convolutions of the brain appeared. Therefore, GAUSSIAN_C gave more successful results since the R1 compartment is a more detailed region. In addition, the affected area in the tumor R4, R5 sections was observed very clearly. Although I have tried every algorithm and value in the R8 section, I can only reveal the convoluted structure of the brain so much.
